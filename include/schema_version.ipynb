{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pyself. Resources\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# My Imports\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "\n",
    "# PySpark Imports\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "class MyFunctions(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.spark = (SparkSession.builder\n",
    "                      .config('spark.jars', 'driver/postgresql-42.6.0.jar')\n",
    "                      .config('spark.driver.extraClassPath', 'driver/postgresql-42.6.0.jar')\n",
    "                      .appName(\"MyProject\").getOrCreate())\n",
    "\n",
    "        self.host = \"localhost\"\n",
    "        self.port = \"5432\"\n",
    "        self.database = \"ensurwave\"\n",
    "        self.username = \"postgres\"\n",
    "        self.password = \"postgres\"\n",
    "        self.url = f\"jdbc:postgresql://{self.host}:{self.port}/{self.database}\"\n",
    "\n",
    "        self.file = 'data/new/20230331_employees_details.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MyFunctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------+-------+-------------------+\n",
      "|id |schema                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |hash                                                            |version|load_timestamp     |\n",
      "+---+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------+-------+-------------------+\n",
      "|1  |StructType([StructField('attributes', StructType([StructField('joinedOn', StringType(), True), StructField('position', StringType(), True), StructField('satisfactionScoe', DoubleType(), True)]), True), StructField('id', StringType(), True), StructField('isDeleted', BooleanType(), True), StructField('name', StringType(), True), StructField('salaryValues', ArrayType(StructType([StructField('currency', StringType(), True), StructField('type', StringType(), True), StructField('value', LongType(), True)]), True), True)])|f7a43c8956169f623d169e5384d2455f249ebbdbffcc4b8433cf253378a7d79c|1      |2023-04-14 11:05:58|\n",
      "+---+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the schema\n",
    "schema_raw_data = str(mf.spark.read.option('inferSchema',True).option('multiline','true').json(mf.file).schema)\n",
    "\n",
    "current_no_space = schema_raw_data.replace(' ','')\n",
    "current_no_space = [i for i in current_no_space]\n",
    "current_no_space.sort()\n",
    "current_no_space = ''.join(current_no_space)\n",
    "\n",
    "current_hash_no_space = hashlib.sha256(current_no_space.encode('utf-8'))\n",
    "current_hash_no_space = current_hash_no_space.hexdigest()\n",
    "\n",
    "# Mounting the dataframe to save the history of schemas used.\n",
    "data = [{'id' : 1, 'schema' : schema_raw_data, 'hash' : current_hash_no_space, 'version' : 1}]\n",
    "current_schema = mf.spark.createDataFrame(data)\n",
    "current_schema = current_schema.select('id','schema','hash','version').withColumn('load_timestamp', to_timestamp(lit(datetime.now().strftime(\"%Y%m%d %H:%M:%S\")),'yyyyMMdd H:m:s'))\n",
    "current_schema.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Current table in \n",
    "try:\n",
    "    table_history = (mf.spark.read.format('jdbc').option('url', mf.url)\n",
    "                        .option('dbtable', 'schema_history')\n",
    "                        .option('user', mf.username)\n",
    "                        .option('password', mf.password)\n",
    "                        .option('driver', 'org.postgresql.Driver').load())\n",
    "\n",
    "    max_value = table_history.select(max(col('id')).alias('max_id'), max(col('version')).alias('max_version')).collect()[0]\n",
    "    max_id, max_version = max_value\n",
    "    new_id, new_version = max_id + 1, max_version + 1\n",
    "\n",
    "    new_value = [{'id':new_id, 'schema':schema_raw_data, 'hash' : current_hash_no_space, 'version':new_version}]\n",
    "\n",
    "    df_new_value = mf.spark.createDataFrame(new_value)\n",
    "    df_new_value = df_new_value.select('id','schema','hash','version').withColumn('load_timestamp', to_timestamp(lit(datetime.now().strftime(\"%Y%m%d %H:%M:%S\")),'yyyyMMdd H:m:s'))\n",
    "\n",
    "    old_hash_schema = table_history.filter(f\"id == ({max_id})\").select('hash').collect()[0][0]\n",
    "    \n",
    "    if old_hash_schema != current_hash_no_space:\n",
    "        df_persist = table_history.unionAll(df_new_value)\n",
    "\n",
    "        df_persist.write.mode('overwrite').saveAsTable('df_persist')\n",
    "\n",
    "        tb_persist = mf.spark.table('df_persist').orderBy(col('id'))\n",
    "\n",
    "        (tb_persist\n",
    "            .write\n",
    "            .mode('overwrite')\n",
    "            .format('jdbc')\n",
    "            .option('url', mf.url)\n",
    "            .option('dbtable', 'schema_history')\n",
    "            .option('user', mf.username)\n",
    "            .option('password', mf.password)\n",
    "            .option('driver', 'org.postgresql.Driver')\n",
    "            .save())\n",
    "        shutil.rmtree(f'{os.getcwd()}/spark-warehouse')\n",
    "# Creating Table\n",
    "except:\n",
    "    print('Nova Tabela')\n",
    "    (current_schema\n",
    "        .write\n",
    "        .format('jdbc')\n",
    "        .option('url', mf.url)\n",
    "        .mode('overwrite')\n",
    "        .option('dbtable', 'schema_history')\n",
    "        .option('user', mf.username)\n",
    "        .option('password', mf.password)\n",
    "        .option('driver', 'org.postgresql.Driver')\n",
    "        .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------+-------+-------------------+\n",
      "|id |schema                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |hash                                                            |version|load_timestamp     |\n",
      "+---+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------+-------+-------------------+\n",
      "|1  |StructType([StructField('attributes', StructType([StructField('joinedOn', StringType(), True), StructField('position', StringType(), True)]), True), StructField('id', StringType(), True), StructField('isDeleted', BooleanType(), True), StructField('name', StringType(), True), StructField('salaryValues', ArrayType(StructType([StructField('currency', StringType(), True), StructField('type', StringType(), True), StructField('value', LongType(), True)]), True), True)])                                                     |c7fba9632ac294248ff90dcb837cb74cd97b2bee7bbb84906bf843adcc44072c|1      |2023-04-14 11:04:53|\n",
      "|2  |StructType([StructField('attributes', StructType([StructField('joinedOn', StringType(), True), StructField('position', StringType(), True), StructField('satisfactionScoe', DoubleType(), True)]), True), StructField('id', StringType(), True), StructField('isDeleted', BooleanType(), True), StructField('name', StringType(), True), StructField('salaryValues', ArrayType(StructType([StructField('currency', StringType(), True), StructField('type', StringType(), True), StructField('value', LongType(), True)]), True), True)])|f7a43c8956169f623d169e5384d2455f249ebbdbffcc4b8433cf253378a7d79c|2      |2023-04-14 11:06:00|\n",
      "+---+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current = (mf.spark.read\n",
    "    .format('jdbc')\n",
    "    .option('url', mf.url)\n",
    "    .option('dbtable', 'schema_history')\n",
    "    .option('user', mf.username)\n",
    "    .option('password', mf.password)\n",
    "    .option('driver', 'org.postgresql.Driver')\n",
    "    .load())\n",
    "current.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'employees_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Marcusso/Documents/git/my_airflow_project/include/schema_version.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Marcusso/Documents/git/my_airflow_project/include/schema_version.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m other_types \u001b[39m=\u001b[39m [column \u001b[39mfor\u001b[39;00m column, datatype \u001b[39min\u001b[39;00m employees_raw\u001b[39m.\u001b[39mdtypes \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mstruct\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m datatype \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39marray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m datatype]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Marcusso/Documents/git/my_airflow_project/include/schema_version.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m struct_types \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcolumn\u001b[39m}\u001b[39;00m\u001b[39m.*\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m column, datatype \u001b[39min\u001b[39;00m employees_raw\u001b[39m.\u001b[39mdtypes \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mstruct\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m datatype \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39marray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m datatype]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Marcusso/Documents/git/my_airflow_project/include/schema_version.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m array_types \u001b[39m=\u001b[39m [column \u001b[39mfor\u001b[39;00m column, datatype \u001b[39min\u001b[39;00m employees_raw\u001b[39m.\u001b[39mdtypes \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39marray\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m datatype]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'employees_raw' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "other_types = [column for column, datatype in employees_raw.dtypes if 'struct' not in datatype and 'array' not in datatype]\n",
    "struct_types = [f'{column}.*' for column, datatype in employees_raw.dtypes if 'struct' in datatype and 'array' not in datatype]\n",
    "array_types = [column for column, datatype in employees_raw.dtypes if 'array' in datatype]\n",
    "\n",
    "# Columns separating structs and array types\n",
    "new = other_types + struct_types + array_types\n",
    "\n",
    "second_change = employees_raw.select(new)\n",
    "\n",
    "for i in array_types:\n",
    "    second_change = second_change.select('*',explode(i).alias(f'{i}_ex')).drop(i).withColumnRenamed(f'{i}_ex',i)\n",
    "    second_change = second_change.select('*',f'{i}.*').drop(i)\n",
    "\n",
    "salary = second_change.select(col('id').alias('id_emp'),'currency','type','value').groupBy('id_emp','currency').pivot('type').sum('value').drop('value','type').dropDuplicates()\n",
    "\n",
    "last_change = second_change.alias('emp').join(salary.alias('sal'), on=col('emp.id')==col('sal.id_emp'), how='inner').drop('id_emp','currency','type','value').dropDuplicates()\n",
    "last_change = last_change.withColumn('loaddate', to_timestamp(lit(datetime.now().strftime(\"%Y%m%d %H:%M:%S\")),'yyyyMMdd H:m:s'))\n",
    "last_change.show()\n",
    "last_change.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (last_change\n",
    "#     .write\n",
    "#     .format('jdbc')\n",
    "#     .option('url', mf.url)\n",
    "#     .mode('overwrite')\n",
    "#     .option('dbtable', 'employee')\n",
    "#     .option('user', mf.username)\n",
    "#     .option('password', mf.password)\n",
    "#     .option('driver', 'org.postgresql.Driver')\n",
    "#     .save())\n",
    "\n",
    "# Pare a sessão Spark\n",
    "# spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|              schema|version|\n",
      "+--------------------+-------+\n",
      "|StructType([Struc...|      1|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(mf.spark.read.format('jdbc').option('url', mf.url)\n",
    "    .option('dbtable', 'schema_version')\n",
    "    .option('user', mf.username)\n",
    "    .option('password', mf.password)\n",
    "    .option('driver', 'org.postgresql.Driver').load().show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
